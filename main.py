# ============================================================
# PROIECT LEARNING ANALYTICS - ACS 2013 (PySpark)
# ============================================================
# Acest script:
#  1) ÃncarcÄƒ setul de date ss13pusa.csv (ACS 2013 Population)
#  2) CurÄƒÈ›Äƒ È™i transformÄƒ datele
#  3) ConstruieÈ™te vectorul de trÄƒsÄƒturi (features)
#  4) AntreneazÄƒ 4 modele de regresie (LR, DT, RF, GBT)
#  5) AntreneazÄƒ un model SVM (LinearSVC) pentru clasificare binarÄƒ a venitului
#  6) EvalueazÄƒ modelele È™i salveazÄƒ graficele Ã®n folderul results/
# ============================================================

import os                         # pentru lucrul cu directoare È™i cÄƒi de fiÈ™iere
import matplotlib.pyplot as plt   # pentru generarea È™i salvarea graficelor

from pyspark.sql import SparkSession
from pyspark.sql import functions as F
from pyspark.sql.types import DoubleType

from pyspark.ml.feature import StringIndexer, VectorAssembler

from pyspark.ml.regression import (
    LinearRegression,
    DecisionTreeRegressor,
    RandomForestRegressor,
    GBTRegressor,
)

from pyspark.ml.evaluation import RegressionEvaluator

from pyspark.ml.classification import LinearSVC
from pyspark.ml.evaluation import MulticlassClassificationEvaluator


# ============================================================
# 0. FUNCÈšIE PRINCIPALÄ‚
# ============================================================

def main():
    # --------------------------------------------------------
    # 0.1. IniÈ›ializare SparkSession
    # --------------------------------------------------------
    # Cream o sesiune Spark â€” punctul de intrare pentru toate operaÈ›iile.
    spark = SparkSession.builder \
        .appName("ACS2013_LearningAnalytics") \
        .getOrCreate()

    print("âœ… Spark pornit, versiune:", spark.version)

    # AsigurÄƒm folderul pentru rezultate (grafice etc.)
    results_dir = "results-updated"
    os.makedirs(results_dir, exist_ok=True)

    # --------------------------------------------------------
    # 1. ÃNCÄ‚RCAREA DATELOR
    # --------------------------------------------------------
    # Presupunem cÄƒ fiÈ™ierul ACS2013.csv este Ã®n directorul data/
    data_path = os.path.join("data", "ACS2013.csv")

    if not os.path.exists(data_path):
        raise FileNotFoundError(
            f"âŒ Nu am gÄƒsit fiÈ™ierul de date la: {os.path.abspath(data_path)}.\n"
            f"   AsigurÄƒ-te cÄƒ ai descÄƒrcat ACS2013.csv din Kaggle È™i l-ai pus Ã®n folderul data/."
        )

    print(f"\nğŸ“¥ Ãncarc datasetul din: {data_path}")

    # Citim CSV-ul cu header È™i inferSchema pentru tipuri automate
    df = spark.read.csv(data_path, header=True, inferSchema=True)

    # print("\nğŸ“Œ Schema originalÄƒ (trunchiatÄƒ):")
    # df.printSchema()

    # --------------------------------------------------------
    # 2. SELECTAREA COLOANELOR RELEVANTE
    # --------------------------------------------------------
    # Folosim:
    #  - AGEP  = vÃ¢rstÄƒ
    #  - SCHL  = nivel educaÈ›ional
    #  - SEX   = gen
    #  - RAC1P = rasÄƒ
    #  - PINCP = venit personal (target pentru regresie)
    cols_interes = ["AGEP", "SCHL", "SEX", "RAC1P", "PINCP"]
    df = df.select(*cols_interes)

    print("\nğŸ“Œ Primele 5 rÃ¢nduri din coloanele de interes:")
    df.show(5)

    # --------------------------------------------------------
    # 3. CURÄ‚ÈšAREA DATELOR
    # --------------------------------------------------------
    # 3.1 EliminÄƒm rÃ¢ndurile cu valori lipsÄƒ Ã®n coloanele importante
    df = df.dropna(subset=["AGEP", "SCHL", "SEX", "RAC1P", "PINCP"])

    # 3.2 EliminÄƒm veniturile <= 0 (coduri invalide / lipsÄƒ)
    df = df.filter(df["PINCP"] > 0)

    # 3.3 Conversia tuturor coloanelor la DoubleType pentru MLlib
    df = df.withColumn("AGEP", F.col("AGEP").cast(DoubleType())) \
           .withColumn("SCHL", F.col("SCHL").cast(DoubleType())) \
           .withColumn("SEX", F.col("SEX").cast(DoubleType())) \
           .withColumn("RAC1P", F.col("RAC1P").cast(DoubleType())) \
           .withColumn("PINCP", F.col("PINCP").cast(DoubleType()))

    print("\nğŸ“Œ Schema dupÄƒ curÄƒÈ›are È™i conversie la DoubleType:")
    df.printSchema()

    # Statistici descriptive pentru vÃ¢rstÄƒ È™i venit
    print("\nğŸ“Š Statistici descriptive (AGEP, PINCP):")
    df.select("AGEP", "PINCP").describe().show()

    # --------------------------------------------------------
    # 4. CODIFICAREA VARIABILELOR CATEGORICE
    # --------------------------------------------------------
    # Folosim StringIndexer pentru:
    #  - SEX   â†’ SEX_idx
    #  - RAC1P â†’ RAC1P_idx
    #  - SCHL  â†’ SCHL_idx

    indexer_sex = StringIndexer(inputCol="SEX",   outputCol="SEX_idx")
    indexer_race = StringIndexer(inputCol="RAC1P", outputCol="RAC1P_idx")
    indexer_edu = StringIndexer(inputCol="SCHL",  outputCol="SCHL_idx")

    df = indexer_sex.fit(df).transform(df)
    df = indexer_race.fit(df).transform(df)
    df = indexer_edu.fit(df).transform(df)

    print("\nğŸ“Œ Exemple de codificare categoricÄƒ (SEX, RAC1P, SCHL):")
    df.select("SEX", "SEX_idx", "RAC1P", "RAC1P_idx", "SCHL", "SCHL_idx") \
      .show(5, truncate=False)

    # --------------------------------------------------------
    # 5. CONSTRUIREA VECTORULUI DE TRÄ‚SÄ‚TURI (features)
    # --------------------------------------------------------
    # CombinÄƒm:
    #  - AGEP
    #  - SEX_idx
    #  - RAC1P_idx
    #  - SCHL_idx
    # Ã®ntr-un singur vector "features".
    assembler = VectorAssembler(
        inputCols=["AGEP", "SEX_idx", "RAC1P_idx", "SCHL_idx"],
        outputCol="features"
    )

    df = assembler.transform(df)

    print("\nğŸ“Œ Exemple din DataFrame-ul final (features + PINCP):")
    df.select("AGEP", "SEX_idx", "RAC1P_idx", "SCHL_idx", "PINCP", "features") \
      .show(5, truncate=False)


    # --------------------------------------------------------
    # 5.1. CLUSTERIZARE CU K-MEANS
    # --------------------------------------------------------
    from pyspark.ml.clustering import KMeans
    from pyspark.ml.evaluation import ClusteringEvaluator

    print("\n======================================")
    print("ğŸ”¶ CLUSTERIZARE: K-Means pe features")
    print("======================================")

    k = 4  # numÄƒr de clustere

    kmeans = KMeans(
        featuresCol="features",
        predictionCol="cluster",
        k=k,
        seed=42
    )

    kmeans_model = kmeans.fit(df)          # âœ” aici df existÄƒ
    df_clusters = kmeans_model.transform(df)

    print("\nğŸ“Œ Primele 10 rÃ¢nduri cu cluster asignat:")
    df_clusters.select(
        "AGEP", "SCHL", "SEX", "RAC1P", "PINCP", "cluster"
    ).show(10, truncate=False)

    # Evaluare Silhouette
    cluster_evaluator = ClusteringEvaluator(
        featuresCol="features",
        predictionCol="cluster",
        metricName="silhouette"
    )
    silhouette = cluster_evaluator.evaluate(df_clusters)
    print(f"\nğŸ“Š Scor Silhouette pentru K={k}: {silhouette:.4f}")

    # Centre clustere
    centers = kmeans_model.clusterCenters()
    print("\nğŸ“ Centre clustere:")
    for i, c in enumerate(centers):
        print(f" Cluster {i}: {c}")

    # Statistici pe cluster
    print("\nğŸ“Š Statistici agregate pe clustere:")
    df_clusters.groupBy("cluster").agg(
        F.count("*").alias("nr_persoane"),
        F.avg("AGEP").alias("varsta_medie"),
        F.avg("SCHL").alias("educatie_medie"),
        F.avg("PINCP").alias("venit_mediu")
    ).orderBy("cluster").show()


    # --------------------------------------------------------
    # 6. ÃMPÄ‚RÈšIREA ÃN SETURI DE TRAIN È˜I TEST
    # --------------------------------------------------------
    # 80% pentru antrenare, 20% pentru test. seed=42 pentru reproductibilitate.
    train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)

    print(f"\nğŸ“¦ Train set: {train_data.count():,} Ã®nregistrÄƒri")
    print(f"ğŸ“¦ Test  set: {test_data.count():,} Ã®nregistrÄƒri")

    # Definim evaluatorii pentru regresie: RMSE È™i RÂ²
    evaluator_rmse = RegressionEvaluator(
        labelCol="PINCP", predictionCol="prediction", metricName="rmse"
    )
    evaluator_r2 = RegressionEvaluator(
        labelCol="PINCP", predictionCol="prediction", metricName="r2"
    )

    # DicÈ›ionare pentru a memora rezultatele modelelor de regresie
    rmse_models = {}
    r2_models = {}

    # --------------------------------------------------------
    # 7. MODEL 1 â€“ REGRESIE LINIARÄ‚
    # --------------------------------------------------------
    print("\n===============================")
    print("ğŸŸ¢ MODEL 1: REGRESIE LINIARÄ‚")
    print("===============================")

    lr = LinearRegression(
        featuresCol="features",
        labelCol="PINCP",
        maxIter=100
    )

    lr_model = lr.fit(train_data)                 # antrenÄƒm modelul
    lr_predictions = lr_model.transform(test_data)  # prezicem pe test

    rmse_lr = evaluator_rmse.evaluate(lr_predictions)
    r2_lr = evaluator_r2.evaluate(lr_predictions)

    rmse_models["LR"] = rmse_lr
    r2_models["LR"] = r2_lr

    print(f"RMSE (LR): {rmse_lr:.2f}")
    print(f"RÂ²   (LR): {r2_lr:.4f}")

    # --------------------------------------------------------
    # 8. MODEL 2 â€“ ARBORE DE DECIZIE
    # --------------------------------------------------------
    print("\n===============================")
    print("ğŸŸ  MODEL 2: ARBORE DE DECIZIE")
    print("===============================")

    dt = DecisionTreeRegressor(
        featuresCol="features",
        labelCol="PINCP",
        maxDepth=10
    )

    dt_model = dt.fit(train_data)
    dt_predictions = dt_model.transform(test_data)

    rmse_dt = evaluator_rmse.evaluate(dt_predictions)
    r2_dt = evaluator_r2.evaluate(dt_predictions)

    rmse_models["DT"] = rmse_dt
    r2_models["DT"] = r2_dt

    print(f"RMSE (DT): {rmse_dt:.2f}")
    print(f"RÂ²   (DT): {r2_dt:.4f}")

    # --------------------------------------------------------
    # 9. MODEL 3 â€“ PÄ‚DURE ALEATORIE (Random Forest)
    # --------------------------------------------------------
    print("\n======================================")
    print("ğŸ”µ MODEL 3: PÄ‚DURE ALEATORIE (RF)")
    print("======================================")

    rf = RandomForestRegressor(
        featuresCol="features",
        labelCol="PINCP",
        numTrees=20,
        maxDepth=10,
        seed=42
    )

    rf_model = rf.fit(train_data)
    rf_predictions = rf_model.transform(test_data)

    rmse_rf = evaluator_rmse.evaluate(rf_predictions)
    r2_rf = evaluator_r2.evaluate(rf_predictions)

    rmse_models["RF"] = rmse_rf
    r2_models["RF"] = r2_rf

    print(f"RMSE (RF): {rmse_rf:.2f}")
    print(f"RÂ²   (RF): {r2_rf:.4f}")

    # --------------------------------------------------------
    # 10. MODEL 4 â€“ GRADIENT-BOOSTED TREES (GBTRegressor)
    # --------------------------------------------------------
    print("\n========================================")
    print("ğŸŸ£ MODEL 4: GRADIENT-BOOSTED TREES (GBT)")
    print("========================================")

    gbt = GBTRegressor(
        featuresCol="features",
        labelCol="PINCP",
        maxDepth=7,      # adÃ¢ncime mai micÄƒ pentru a reduce overfitting
        maxIter=50,      # numÄƒr de iteratii (boosting rounds)
        stepSize=0.1,
        seed=42
    )

    gbt_model = gbt.fit(train_data)
    gbt_predictions = gbt_model.transform(test_data)

    rmse_gbt = evaluator_rmse.evaluate(gbt_predictions)
    r2_gbt = evaluator_r2.evaluate(gbt_predictions)

    rmse_models["GBT"] = rmse_gbt
    r2_models["GBT"] = r2_gbt

    print(f"RMSE (GBT): {rmse_gbt:.2f}")
    print(f"RÂ²   (GBT): {r2_gbt:.4f}")

    # --------------------------------------------------------
    # 11. MODEL 5 â€“ SVM (LinearSVC) PENTRU CLASIFICARE BINARÄ‚
    # --------------------------------------------------------
    print("\n====================================================")
    print("ğŸ§© MODEL 5: SVM (LinearSVC) â€“ CLASIFICARE VENIT BINAR")
    print("====================================================")

    # 11.1 CalculÄƒm mediana venitului din train (prag pentru venit "ridicat")
    median_income = train_data.approxQuantile("PINCP", [0.5], 0.01)[0]
    print(f"Prag (medianÄƒ PINCP): {median_income:.2f}")

    # 11.2 CreÄƒm eticheta binarÄƒ label_bin: 1 dacÄƒ PINCP >= medianÄƒ, altfel 0
    train_cls = train_data.withColumn(
        "label_bin",
        (F.col("PINCP") >= F.lit(median_income)).cast("int")
    )
    test_cls = test_data.withColumn(
        "label_bin",
        (F.col("PINCP") >= F.lit(median_income)).cast("int")
    )

    # 11.3 Definim modelul LinearSVC (SVM liniar)
    svm = LinearSVC(
        featuresCol="features",
        labelCol="label_bin",
        maxIter=100,
        regParam=0.01
    )

    svm_model = svm.fit(train_cls)
    svm_predictions = svm_model.transform(test_cls)

    # 11.4 EvaluÄƒm clasificarea cu accuracy, F1, precision È™i recall
    evaluator_acc = MulticlassClassificationEvaluator(
        labelCol="label_bin", predictionCol="prediction", metricName="accuracy"
    )
    evaluator_f1 = MulticlassClassificationEvaluator(
        labelCol="label_bin", predictionCol="prediction", metricName="f1"
    )
    evaluator_prec = MulticlassClassificationEvaluator(
        labelCol="label_bin", predictionCol="prediction", metricName="precisionByLabel"
    )
    evaluator_rec = MulticlassClassificationEvaluator(
        labelCol="label_bin", predictionCol="prediction", metricName="recallByLabel"
    )

    acc_svm = evaluator_acc.evaluate(svm_predictions)
    f1_svm = evaluator_f1.evaluate(svm_predictions)
    prec_svm = evaluator_prec.evaluate(svm_predictions)
    rec_svm = evaluator_rec.evaluate(svm_predictions)

    print(f"Accuracy (SVM):  {acc_svm:.4f}")
    print(f"F1-score (SVM):  {f1_svm:.4f}")
    print(f"Precision (SVM): {prec_svm:.4f}")
    print(f"Recall (SVM):    {rec_svm:.4f}")



    # --------------------------------------------------------
    # 12. VIZUALIZARE â€“ GRAFICE PENTRU REGRESIE
    # --------------------------------------------------------
    print("\nğŸ“Š Generez graficele pentru regresie È™i SVM...")

    # 12.1 Bar chart pentru RMSE (LR, DT, RF, GBT)
    models_reg = list(rmse_models.keys())   # ["LR", "DT", "RF", "GBT"]
    rmse_vals = [rmse_models[m] for m in models_reg]
    r2_vals = [r2_models[m] for m in models_reg]

    # Grafic RMSE
    plt.figure(figsize=(8, 5))
    plt.bar(models_reg, rmse_vals)
    plt.title("RMSE â€“ comparaÈ›ie modele de regresie")
    plt.ylabel("RMSE")
    plt.grid(axis="y", linestyle="--", alpha=0.6)
    plt.tight_layout()
    rmse_img_path = os.path.join(results_dir, "comparatie_rmse_extins.png")
    plt.savefig(rmse_img_path)
    plt.close()

    # Grafic RÂ²
    plt.figure(figsize=(8, 5))
    plt.bar(models_reg, r2_vals)
    plt.title("RÂ² â€“ comparaÈ›ie modele de regresie")
    plt.ylabel("RÂ²")
    plt.ylim(0, 1)
    plt.grid(axis="y", linestyle="--", alpha=0.6)
    plt.tight_layout()
    r2_img_path = os.path.join(results_dir, "comparatie_r2_extins.png")
    plt.savefig(r2_img_path)
    plt.close()

    # --------------------------------------------------------
    # 13. VIZUALIZARE â€“ PERFORMANÈšÄ‚ SVM (Accuracy È™i F1)
    # --------------------------------------------------------
    plt.figure(figsize=(6, 5))
    metrics_cls = ["Accuracy", "F1-score"]
    vals_cls = [acc_svm, f1_svm]
    plt.bar(metrics_cls, vals_cls)
    plt.title("PerformanÈ›a clasificÄƒrii â€“ SVM (venit â‰¥ medianÄƒ?)")
    plt.ylim(0, 1)
    plt.grid(axis="y", linestyle="--", alpha=0.6)
    plt.tight_layout()
    svm_img_path = os.path.join(results_dir, "comparatie_svm_cls.png")
    plt.savefig(svm_img_path)
    plt.close()

    # --------------------------------------------------------
    # 14. VIZUALIZARE â€“ SCATTER PENTRU PREDICÈšII RF VS VALORI REALE
    # --------------------------------------------------------
    # Folosim un eÈ™antion mic pentru scatter, altfel ar fi enorm.
    sample_rf = rf_predictions.select("PINCP", "prediction").sample(
        fraction=0.001, seed=42
    )
    sample_pd = sample_rf.toPandas()  # convertim la pandas pentru matplotlib

    plt.figure(figsize=(6, 6))
    plt.scatter(sample_pd["PINCP"], sample_pd["prediction"], s=10, alpha=0.4)
    max_val = sample_pd["PINCP"].max()
    plt.plot([0, max_val], [0, max_val], color="red", linewidth=2, label="y = x")
    plt.title("PredicÈ›ii vs valori reale (Random Forest)")
    plt.xlabel("PINCP real")
    plt.ylabel("PINCP prezis")
    plt.legend()
    plt.grid(alpha=0.5)
    plt.tight_layout()
    scatter_img_path = os.path.join(results_dir, "scatter_pred_vs_real_rf.png")
    plt.savefig(scatter_img_path)
    plt.close()

    # --------------------------------------------------------
    # 15. REZUMAT FINAL
    # --------------------------------------------------------
    print("\nâœ… GATA! Rezumat modele regresie:")
    print(f"{'Model':6s} | {'RMSE':>12s} | {'RÂ²':>8s}")
    print("-" * 32)
    for m in models_reg:
        print(f"{m:6s} | {rmse_models[m]:12.2f} | {r2_models[m]:8.4f}")

    print("\nâœ… PerformanÈ›Äƒ SVM (clasificare venit ridicat):")
    print(f"Accuracy:  {acc_svm:.4f}")
    print(f"F1-score:  {f1_svm:.4f}")
    print(f"Precision: {prec_svm:.4f}")
    print(f"Recall:    {rec_svm:.4f}")

    print("\nğŸ“‚ Grafice salvate Ã®n folderul:", os.path.abspath(results_dir))
    print(" -", rmse_img_path)
    print(" -", r2_img_path)
    print(" -", svm_img_path)
    print(" -", scatter_img_path)

    # Oprirea sesiunii Spark
    spark.stop()
    print("\nğŸ‘‹ Spark oprit. Script terminat.")


# ============================================================
# PUNCTUL DE INTRARE
# ============================================================

if __name__ == "__main__":
    main()
